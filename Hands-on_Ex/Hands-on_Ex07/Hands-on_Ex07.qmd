---
title: "Hands-On Exercise 7: Global & Local Measures of Spatial Autocorrelation"
date: "19 February 2023"
date-modified: "`r Sys.Date()`"
number-sections: true
format: html
execute: 
  eval: true
  echo: true
  warning: false
editor: visual
---

# Getting Started

## Analytical QUestion

In spatial policy, one of the main development objective of the local government and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is No. Then, our next question will be "is there sign of spatial clustering?". And, if the answer for this question is yes, then our next question will be "where are these clusters?"

In this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China.

## Study Area and Data

-   Hunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.
-   Hunan_2012.csv: This csv file contains selected Hunan's local development indicators in 2012.

## Loading and Installing R packages

```{r}
pacman::p_load(sf, spdep, tmap, tidyverse)
```

# Getting Data in R Environment

## Importing shapefile into R

```{r}
hunan <- st_read(dsn= "data/geospatial",
                 layer = "Hunan")
```

## Importing csv fule into R

```{r}
hunan2012 <- read_csv("data/aspatial/Hunan_2012.csv")
```

## Performing Relational Join

```{r}
hunan <- left_join(hunan, hunan2012) %>%
  select(1:4, 7, 15)
```

## Viewing Regional Development Indicator

Creating a map to show the distribution of GDPPC 2012

```{r}
equal <- tm_shape(hunan) + 
  tm_fill("GDPPC",
          n = 5,
          style = "equal") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Equal Interval Classification")

quantile <- tm_shape(hunan) +
  tm_fill("GDPPC",
          n = 5,
          style = "quantile") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Equal Quantile Classification")

tmap_arrange(equal,
             quantile,
             asp=1,
             ncol=2)
```

# Global Spatial Autocorrelation

In this section, we will compute global spatial autocorrelation statistics and perform spatial complete randomness test for global spatial autocorrelation.

## Computing Contiguity Spatial Weights

Before computing global spatial autocorrelations statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between geographical units in the study area.

We will use poly2nb() to compute contiguity weight matrices for the study area. It builds a neighbours list based on regions with contiguous boundaries.

If you look at the documentation you will see that you can pass a "queen" argument that takes TRUE or FALSE as options. If you do not specify this argument the default is set to TRUE, that is, if you don't specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.

```{r}
wm_q <- poly2nb(hunan,
                queen = TRUE)
summary(wm_q)
```

The summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbours

## Row Standardised weights matrix

Next, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style="W"). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values.

While this is the most intuitive way to summarise the neighbors' values, it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons, thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data.

For this example, we'll stick with the style="W" option for simplicity's sake but note that other more robust options are available, notably style="B".

```{r}
rswm_q <- nb2listw(wm_q,
                   style="W",
                   zero.policy = TRUE)
rswm_q
```

The input of nb2listw() must be object of class **nb**. The syntax of the function takes in 2 arguments, style and zero.poly.

*style* can take values "W", "B", "C", "U", "minmax", and "S".

-   B is basic binary coding

-   W is row standardised (sums over all links to n)

-   C is globally standardised (sums over all links to n)

-   U is equal to C divided by the number of neighbours (sums over all links to unity)

-   S is the variance stabilising coding scheme (sums over all links to n)

If zero policy is set to TRUE, weights vectors of zero length are inserted for regions without neighbours in the neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length=length(neighbours))) %\*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice.

#Global Spatial Autocorrelation: Moran's I Test

In this section, we will perform Moran's I statistics testing using moran.test() from spdep.

```{r}
moran.test(hunan$GDPPC,
           listw = rswm_q,
           zero.policy = TRUE,
           na.action = na.omit)
```

**What statistical conclusions can be drawn from the output?**

## Computing Monte Carlo Moran's I

The code chunk below performs permutation test for Moranâ€™s I statistic by using moran.mc() of spdep. A total of 1000 simulations will be performed.

```{r}

```
